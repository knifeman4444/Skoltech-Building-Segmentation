{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 1514093,
     "sourceType": "datasetVersion",
     "datasetId": 892049
    },
    {
     "sourceId": 7037880,
     "sourceType": "datasetVersion",
     "datasetId": 4048155
    }
   ],
   "dockerImageVersionId": 30587,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from skimage.util import random_noise\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-24T08:38:48.284466Z",
     "iopub.execute_input": "2023-11-24T08:38:48.285221Z",
     "iopub.status.idle": "2023-11-24T08:38:53.908506Z",
     "shell.execute_reply.started": "2023-11-24T08:38:48.285180Z",
     "shell.execute_reply": "2023-11-24T08:38:53.907710Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:15.125181082Z",
     "start_time": "2023-11-24T20:27:13.458000575Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def default_aug(image, mask):\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def default_preprocessing(image):\n",
    "    return torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "\n",
    "\n",
    "class SegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 tiles,\n",
    "                 masks,\n",
    "                 augmentations,  # Augmentations\n",
    "                 preprocessing   # Processing data for the model\n",
    "                 ):\n",
    "        self.has_mask = masks is not None\n",
    "        self.tiles = tiles\n",
    "        self.masks = masks\n",
    "        self.augmentations = augmentations\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tiles)\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        image = self.tiles[idx]\n",
    "        mask = None\n",
    "        if self.has_mask:\n",
    "            mask = self.masks[idx]\n",
    "        image, mask = self.augmentations(image, mask)\n",
    "        if self.has_mask:\n",
    "            mask = torch.from_numpy(mask).float()\n",
    "        before_preprocessing = image\n",
    "        image = self.preprocessing(image)\n",
    "\n",
    "        return image, mask, before_preprocessing\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask, before_preprocessing = self.get_item(idx)\n",
    "        if self.has_mask:\n",
    "            return image, mask\n",
    "        return image\n",
    "\n",
    "\n",
    "def get_tiles(tile_size,\n",
    "              path_to_pics,\n",
    "              path_to_masks=None,  # None if there are no labels\n",
    "              ):\n",
    "    # Images loading\n",
    "    images = []\n",
    "    masks = None\n",
    "    for root, dirs, files in os.walk(path_to_pics):\n",
    "        for file in sorted(files):\n",
    "            img = cv2.imread(os.path.join(root, file))\n",
    "            h, w, _ = img.shape\n",
    "\n",
    "            for h_coord in range(0, h // tile_size):\n",
    "                for w_coord in range(0, w // tile_size):\n",
    "                    y = h_coord * tile_size\n",
    "                    x = w_coord * tile_size\n",
    "                    images.append(img[y: y + tile_size, x: x + tile_size])\n",
    "\n",
    "    # Masks loading\n",
    "    if path_to_masks is not None:\n",
    "        masks = []\n",
    "        for root, dirs, files in os.walk(path_to_masks):\n",
    "            for file in sorted(files):\n",
    "                mask = cv2.imread(os.path.join(root, file))\n",
    "                mask = (mask[:, :, 0] > 0).astype('uint8')\n",
    "                h, w = mask.shape\n",
    "\n",
    "                for h_coord in range(0, h // tile_size):\n",
    "                    for w_coord in range(0, w // tile_size):\n",
    "                        y = h_coord * tile_size\n",
    "                        x = w_coord * tile_size\n",
    "                        masks.append(mask[y: y + tile_size, x: x + tile_size])\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def get_datasets(tile_size,\n",
    "                 path_to_pics,\n",
    "                 path_to_masks=None,\n",
    "                 augmentations=default_aug,            # Augmentations\n",
    "                 preprocessing=default_preprocessing   # Processing data for the model\n",
    "                 ):\n",
    "    tiles, masks = get_tiles(tile_size, path_to_pics, path_to_masks)\n",
    "    train_tiles, val_tiles, train_masks, val_masks = train_test_split(tiles, masks, test_size=0.2, random_state=42)\n",
    "    train_dataset = SegmentationDataset(train_tiles, train_masks, augmentations, preprocessing)\n",
    "    val_dataset = SegmentationDataset(val_tiles, val_masks, default_aug, preprocessing)\n",
    "    return train_dataset, val_dataset\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T08:38:53.909737Z",
     "iopub.execute_input": "2023-11-24T08:38:53.910052Z",
     "iopub.status.idle": "2023-11-24T08:38:54.511809Z",
     "shell.execute_reply.started": "2023-11-24T08:38:53.910026Z",
     "shell.execute_reply": "2023-11-24T08:38:54.511020Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:15.369710067Z",
     "start_time": "2023-11-24T20:27:15.129606169Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BACKBONE = 'timm-efficientnet-b5'\n",
    "PRETRAIN = \"imagenet\"\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(BACKBONE, pretrained=PRETRAIN)\n",
    "\n",
    "def preprocessing(image):\n",
    "    image = preprocessing_fn(image)\n",
    "    return torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "\n",
    "def augmentations(image, mask):\n",
    "    # Random turn\n",
    "    if random.randint(1, 2) == 1:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "    if random.randint(1, 2) == 1:\n",
    "        image = cv2.flip(image, 0)\n",
    "        mask = cv2.flip(mask, 0)\n",
    "\n",
    "    # Color augmentations\n",
    "    ch_col = random.randint(80, 120) / 100\n",
    "    image = image.astype('float64') * ch_col\n",
    "    image[image > 255] = 255\n",
    "    image = image.astype('uint8')\n",
    "    return image, mask\n",
    "\n",
    "dataset_train, dataset_val = get_datasets(256,\n",
    "                                          'data/train/images',\n",
    "                                          'data/train/masks',\n",
    "                                          augmentations=augmentations,\n",
    "                                          preprocessing=preprocessing)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T09:20:19.014562Z",
     "iopub.execute_input": "2023-11-24T09:20:19.015136Z",
     "iopub.status.idle": "2023-11-24T09:20:48.487408Z",
     "shell.execute_reply.started": "2023-11-24T09:20:19.015106Z",
     "shell.execute_reply": "2023-11-24T09:20:48.486620Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:28.925778203Z",
     "start_time": "2023-11-24T20:27:15.370780277Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=14, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=14, shuffle=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T09:20:48.488813Z",
     "iopub.execute_input": "2023-11-24T09:20:48.489120Z",
     "iopub.status.idle": "2023-11-24T09:20:48.493933Z",
     "shell.execute_reply.started": "2023-11-24T09:20:48.489096Z",
     "shell.execute_reply": "2023-11-24T09:20:48.492713Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:28.927540070Z",
     "start_time": "2023-11-24T20:27:28.926139126Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = smp.PAN(\n",
    "    encoder_name=BACKBONE,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation='sigmoid'\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T09:20:48.495291Z",
     "iopub.execute_input": "2023-11-24T09:20:48.495579Z",
     "iopub.status.idle": "2023-11-24T09:20:51.182204Z",
     "shell.execute_reply.started": "2023-11-24T09:20:48.495551Z",
     "shell.execute_reply": "2023-11-24T09:20:51.181175Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:29.161024705Z",
     "start_time": "2023-11-24T20:27:28.927652558Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "TEAM_NAME = \"knife_team\"\n",
    "PROJECT_NAME = \"building-segmentation\"\n",
    "\n",
    "\n",
    "class SegmentationModel:\n",
    "    def __init__(self, model: torch.nn.Module, model_name: str = \"model\", device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def train(self, loss, train_loader, val_loader,\n",
    "              metrics: dict, optimizer, target_metric=\"f1\",\n",
    "              epochs=100, wandb_logging=False, path_to_save_model=None,\n",
    "              verbose=True):\n",
    "\n",
    "        if wandb_logging:\n",
    "            run = wandb.init(\n",
    "                entity=TEAM_NAME,\n",
    "                project=PROJECT_NAME,\n",
    "                config={\n",
    "                    \"architecture\": self.model_name,\n",
    "                    \"epochs\": epochs,\n",
    "                    \"batch_size\": train_loader.batch_size,\n",
    "                    \"optimizer\": optimizer.__class__.__name__,\n",
    "                    \"loss\": loss.__class__.__name__,\n",
    "                    \"lr\": optimizer.param_groups[0]['lr'],\n",
    "                    \"target_metric\": target_metric,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        best_metric = 0\n",
    "        train_logs_list, valid_logs_list = [], []\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            self.model.train()\n",
    "            results = {}\n",
    "            for metric_name, metric in metrics.items():\n",
    "                results[metric_name] = []\n",
    "            results['train_loss'] = []\n",
    "\n",
    "            pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "            pbar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            # Train cycle\n",
    "            for batch_idx, (data, target) in pbar:\n",
    "                data, target = data.to(self.device), target.to(self.device).unsqueeze(1)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss_value = loss(output, target)\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Train metrics\n",
    "                results['train_loss'].append(loss_value.item())\n",
    "                for metric_name, metric in metrics.items():\n",
    "                    results[metric_name].append(metric(output, target).detach().cpu().item())\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    \"loss\": numpy.mean(results['train_loss']),\n",
    "                })\n",
    "\n",
    "            results['train_loss'] = numpy.mean(results['train_loss'])\n",
    "            for metric_name, metric in metrics.items():\n",
    "                results[metric_name] = numpy.mean(results[metric_name])\n",
    "\n",
    "            train_logs_list.append(results)\n",
    "            if verbose:\n",
    "                print(f'Train logs: {results}')\n",
    "\n",
    "            results = {}\n",
    "            for metric_name, metric in metrics.items():\n",
    "                results[metric_name] = []\n",
    "            results['val_loss'] = []\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, target) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "                    data, target = data.to(self.device), target.to(self.device).unsqueeze(1)\n",
    "                    output = self.model(data)\n",
    "                    loss_value = loss(output, target)\n",
    "                    \n",
    "                    results['val_loss'].append(loss_value.item())\n",
    "                    for metric_name, metric in metrics.items():\n",
    "                        results[metric_name].append(metric(output, target).detach().cpu().item())\n",
    "\n",
    "            results['val_loss'] = numpy.mean(results['val_loss'])\n",
    "            for metric_name, metric in metrics.items():\n",
    "                results[metric_name] = numpy.mean(results[metric_name])\n",
    "            valid_logs_list.append(results)\n",
    "\n",
    "            if verbose:\n",
    "                print(f'Val logs: {results}')\n",
    "\n",
    "            # Saving the model\n",
    "            if results[target_metric] > best_metric:\n",
    "                print(f'New best model! Val {target_metric}: {results[target_metric]}')\n",
    "                best_metric = results[target_metric]\n",
    "                if path_to_save_model is not None:\n",
    "                    model_path = os.path.join(path_to_save_model, f'{self.model_name}_{round(best_metric, 4)}.pth')\n",
    "                    torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "            if wandb_logging:\n",
    "                wandb.log({\"train_loss\": train_logs_list[-1]['train_loss'],\n",
    "                           \"val_loss\": valid_logs_list[-1]['val_loss']})\n",
    "\n",
    "                for metric_name, metric in metrics.items():\n",
    "                    wandb.log({f\"train_{metric_name}\": train_logs_list[-1][metric_name],\n",
    "                               f\"val_{metric_name}\": valid_logs_list[-1][metric_name]})\n",
    "\n",
    "        if wandb_logging:\n",
    "            run.finish()\n",
    "\n",
    "        return train_logs_list, valid_logs_list\n",
    "\n",
    "    def predict(self, test_loader):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            for batch_idx, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "                try:\n",
    "                    data, target = data\n",
    "                    data, target = data.to(self.device), target.to(self.device).unsqueeze(1)\n",
    "                except TypeError:\n",
    "                    data = data.to(self.device)\n",
    "                output = self.model(data).detach().cpu().numpy()\n",
    "                for part in output:\n",
    "                    predictions.append(part[0])\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:15:46.786825Z",
     "iopub.execute_input": "2023-11-24T10:15:46.787234Z",
     "iopub.status.idle": "2023-11-24T10:15:46.814536Z",
     "shell.execute_reply.started": "2023-11-24T10:15:46.787203Z",
     "shell.execute_reply": "2023-11-24T10:15:46.813466Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:29.177211785Z",
     "start_time": "2023-11-24T20:27:29.161201382Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:29.265417520Z",
     "start_time": "2023-11-24T20:27:29.168395949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model_train = SegmentationModel(model, f'PAN-{BACKBONE}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T20:27:29.413814344Z",
     "start_time": "2023-11-24T20:27:29.266448031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpaspasuy\u001B[0m (\u001B[33mknife_team\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/pavel/ML/sseg/skoltech_Infrastructure/wandb/run-20231124_232730-j3v53al1</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/knife_team/building-segmentation/runs/j3v53al1' target=\"_blank\">solar-elevator-29</a></strong> to <a href='https://wandb.ai/knife_team/building-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/knife_team/building-segmentation' target=\"_blank\">https://wandb.ai/knife_team/building-segmentation</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/knife_team/building-segmentation/runs/j3v53al1' target=\"_blank\">https://wandb.ai/knife_team/building-segmentation/runs/j3v53al1</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 692/692 [04:38<00:00,  2.48it/s, loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.794218451807523, 'train_loss': 0.3836157320207254}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:20<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8477157536958684, 'val_loss': 0.29044856811534464}\n",
      "New best model! Val f1: 0.8477157536958684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 692/692 [04:37<00:00,  2.50it/s, loss=0.283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.8507938805343098, 'train_loss': 0.2832237013502617}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.860935891294755, 'val_loss': 0.2638193155299721}\n",
      "New best model! Val f1: 0.860935891294755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 692/692 [04:42<00:00,  2.45it/s, loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.8635163219333384, 'train_loss': 0.25818017822814127}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.866225158892615, 'val_loss': 0.252340308159073}\n",
      "New best model! Val f1: 0.866225158892615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 692/692 [04:34<00:00,  2.52it/s, loss=0.237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.874676485454416, 'train_loss': 0.23657636034350865}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8705851380535633, 'val_loss': 0.2441580932953454}\n",
      "New best model! Val f1: 0.8705851380535633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 692/692 [04:44<00:00,  2.43it/s, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.881757160142667, 'train_loss': 0.22312413474727918}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8711190447641936, 'val_loss': 0.24235271787367804}\n",
      "New best model! Val f1: 0.8711190447641936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 692/692 [04:30<00:00,  2.56it/s, loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.8871019030409741, 'train_loss': 0.2129389067433473}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8711944387827305, 'val_loss': 0.2418928697619135}\n",
      "New best model! Val f1: 0.8711944387827305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 692/692 [04:27<00:00,  2.58it/s, loss=0.202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.892901382435953, 'train_loss': 0.20181074144178732}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8744183237842053, 'val_loss': 0.23590297058138543}\n",
      "New best model! Val f1: 0.8744183237842053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 692/692 [04:27<00:00,  2.58it/s, loss=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.8967357943685068, 'train_loss': 0.19444798045075698}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8727697109900459, 'val_loss': 0.2386054220916219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 692/692 [04:36<00:00,  2.50it/s, loss=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9000685911819425, 'train_loss': 0.1881779125660141}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:20<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8740775233748331, 'val_loss': 0.2367624388953854}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 692/692 [04:36<00:00,  2.50it/s, loss=0.175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9070152295807193, 'train_loss': 0.17499532511813104}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8737580659072524, 'val_loss': 0.23682915785409123}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 692/692 [04:31<00:00,  2.55it/s, loss=0.169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9100560795709577, 'train_loss': 0.1693261246805246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.871358471798759, 'val_loss': 0.24209706872873912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 692/692 [04:32<00:00,  2.54it/s, loss=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9120282500637749, 'train_loss': 0.16560156298855136}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.876795468647356, 'val_loss': 0.23069607729167607}\n",
      "New best model! Val f1: 0.876795468647356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 692/692 [04:32<00:00,  2.54it/s, loss=0.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9149692215326893, 'train_loss': 0.16009883651499116}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.875690049863275, 'val_loss': 0.23290559873415556}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 692/692 [04:39<00:00,  2.48it/s, loss=0.157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.916760786506482, 'train_loss': 0.15674485292048812}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:20<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8767502114951955, 'val_loss': 0.23106222655731817}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 692/692 [04:33<00:00,  2.53it/s, loss=0.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9202768893083396, 'train_loss': 0.15010997997543027}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8740996804540557, 'val_loss': 0.2358743138395982}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 692/692 [04:31<00:00,  2.55it/s, loss=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9200576086437082, 'train_loss': 0.15053081159302265}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8744610954571321, 'val_loss': 0.23548302691795922}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 692/692 [04:31<00:00,  2.55it/s, loss=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9215223930474651, 'train_loss': 0.14769154718156494}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.874130931203765, 'val_loss': 0.23570475412931055}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 692/692 [04:37<00:00,  2.49it/s, loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9235046922816017, 'train_loss': 0.14391325517541412}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8756222246010179, 'val_loss': 0.2330293896570371}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 692/692 [04:37<00:00,  2.49it/s, loss=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9284202815652582, 'train_loss': 0.13480502013870746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:20<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8772975247719385, 'val_loss': 0.22984730956182314}\n",
      "New best model! Val f1: 0.8772975247719385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 692/692 [04:34<00:00,  2.52it/s, loss=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9313656214000172, 'train_loss': 0.12917389380449504}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:20<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8774055297664135, 'val_loss': 0.22964163805018958}\n",
      "New best model! Val f1: 0.8774055297664135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 692/692 [04:39<00:00,  2.48it/s, loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9325843870295265, 'train_loss': 0.12690743433602283}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8742248374602698, 'val_loss': 0.23570029583969557}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 692/692 [04:30<00:00,  2.56it/s, loss=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9318946396684371, 'train_loss': 0.12821654932347337}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8754431043746155, 'val_loss': 0.23353445219855778}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 692/692 [04:39<00:00,  2.48it/s, loss=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9342985629518598, 'train_loss': 0.12374379137003352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:18<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8754400728065843, 'val_loss': 0.2332454241080091}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 692/692 [04:44<00:00,  2.44it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9346461004949029, 'train_loss': 0.12307157595722662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8737506559818466, 'val_loss': 0.2362012687446065}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 692/692 [04:47<00:00,  2.41it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train logs: {'f1': 0.9346089558622052, 'train_loss': 0.12307887080776898}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:19<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val logs: {'f1': 0.8760840779095027, 'val_loss': 0.23203207647180282}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26:  10%|█         | 71/692 [00:29<04:17,  2.41it/s, loss=0.114]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 20\u001B[0m\n\u001B[1;32m     15\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdamW(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3e-4\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n\u001B[1;32m     16\u001B[0m metrics \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m: my_f1_score,\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m#'iou': smp.utils.metrics.IoU(threshold=0.5)\u001B[39;00m\n\u001B[1;32m     19\u001B[0m }\n\u001B[0;32m---> 20\u001B[0m \u001B[43mmodel_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwandb_logging\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mpath_to_save_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbaseline_checkpoints/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 60\u001B[0m, in \u001B[0;36mSegmentationModel.train\u001B[0;34m(self, loss, train_loader, val_loader, metrics, optimizer, target_metric, epochs, wandb_logging, path_to_save_model, verbose)\u001B[0m\n\u001B[1;32m     57\u001B[0m loss_value\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     58\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 60\u001B[0m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m metric_name, metric \u001B[38;5;129;01min\u001B[39;00m metrics\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     62\u001B[0m     results[metric_name]\u001B[38;5;241m.\u001B[39mappend(metric(output, target)\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mitem())\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from segmentation_models_pytorch import utils\n",
    "\n",
    "f1_score = smp.utils.metrics.Fscore(threshold=0.5)\n",
    "def my_f1_score(y_pred, y_true):\n",
    "    score = (f1_score(y_pred, y_true) + f1_score(1 - y_pred, 1 - y_true)) / 2\n",
    "    return score\n",
    "\n",
    "\n",
    "def my_dice_loss(p, y):\n",
    "    loss = 1 - (2 * (p * y).sum() + 1) / (p.sum() + y.sum() + 1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "criterion = my_dice_loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
    "metrics = {\n",
    "    'f1': my_f1_score,\n",
    "    'iou': smp.utils.metrics.IoU(threshold=0.5)\n",
    "}\n",
    "model_train.train(criterion, dataloader_train, dataloader_val, metrics, optimizer, wandb_logging=True,\n",
    "                 path_to_save_model='baseline_checkpoints/')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T22:31:06.220472879Z",
     "start_time": "2023-11-24T20:27:29.453976063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = model_train.predict(dataloader_val)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:15:53.917812Z",
     "iopub.execute_input": "2023-11-24T10:15:53.918422Z",
     "iopub.status.idle": "2023-11-24T10:16:08.986841Z",
     "shell.execute_reply.started": "2023-11-24T10:15:53.918393Z",
     "shell.execute_reply": "2023-11-24T10:16:08.985915Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T22:31:06.222756635Z",
     "start_time": "2023-11-24T22:31:06.222346191Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize(figsize=(20, 10), **images):\n",
    "    \"\"\"\n",
    "    :param figsize: A tuple (width, height) specifying the size of the figure. Default is (20, 10).\n",
    "    :param images: Keyword arguments where the key is the name of the image and the value is the corresponding image data.\n",
    "    :return: None\n",
    "\n",
    "    This method takes in multiple images and displays them in a grid layout using matplotlib. It supports numpy arrays and torch tensors as image data. The figsize parameter allows you to specify the size of the figure. Each image will be displayed with its corresponding name as the title.\n",
    "\n",
    "    Examples:\n",
    "        visualize(figsize=(10, 5), image1=image_data1, image2=image_data2)\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.detach().cpu().numpy()\n",
    "            if image.shape[0] == 1:\n",
    "                image = image[0]\n",
    "\n",
    "            if len(image.shape) == 3:\n",
    "                image = image.transpose(1, 2, 0)\n",
    "\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise ValueError(f'Image must be numpy array or torch tensor. Got {type(image)}')\n",
    "        if image.shape[-1] == 1:\n",
    "            image = image[:, :, 0]\n",
    "\n",
    "        plt.subplot(1, n_images, idx + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(name.replace('_', ' ').title(), fontsize=20)\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:23:16.701235Z",
     "iopub.execute_input": "2023-11-24T10:23:16.701849Z",
     "iopub.status.idle": "2023-11-24T10:23:16.713398Z",
     "shell.execute_reply.started": "2023-11-24T10:23:16.701818Z",
     "shell.execute_reply": "2023-11-24T10:23:16.712234Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-24T22:31:06.222424030Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(30):\n",
    "    params_vis = {}\n",
    "    params_vis[f'image{i}'] = dataset_val.get_item(i)[2]\n",
    "    params_vis[f'true_mask{i}'] = dataset_val.get_item(i)[1]\n",
    "    params_vis[f'pred_mask{i}'] = predictions[i]\n",
    "    visualize(figsize=(20, 10), **params_vis)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:39:38.589184Z",
     "iopub.execute_input": "2023-11-24T10:39:38.590235Z",
     "iopub.status.idle": "2023-11-24T10:39:51.656108Z",
     "shell.execute_reply.started": "2023-11-24T10:39:38.590193Z",
     "shell.execute_reply": "2023-11-24T10:39:51.655070Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-24T22:31:06.223731460Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
